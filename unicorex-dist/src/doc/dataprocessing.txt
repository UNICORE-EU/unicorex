[[ux_dataprocessing]]

Data-triggered processing
-------------------------

UNICORE can be set up to automatically scan storages and trigger processing
steps (e.g. submit batch jobs or run processing tasks) according to 
user-defined rules.

Enabling and disabling data-triggered processing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

By default, data-triggered processing is disabled on all storages.

Explicit control is available via the configuration properties 
for storages, as listed in xref:ux_storages[] Set the 'enableTrigger' property 
to "true" to enable the data-triggered processing for the given storage.

Controlling the scanning process
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To control which directories should be scanned, a file named +.UNICORE_Rules+
at the top-level of the storage is read and evaluated. This file can be (and 
usually will be) edited and uploaded by the user.

The file must be in JSON format, and has the following elements:

----------------------------
{
"DirectoryScan": {

  "IncludeDirs": [
      "project.*",
  ],
  "ExcludeDirs": [
      "project42",
  ],
  "Interval": "30",

},

"Rules": [ ]

}
----------------------------

The "IncludeDirs" and "ExcludeDirs" are lists of Java regular expression strings that denote 
directories (as always relative to the storage root) that should be included or excluded from
the scan.

The "Rules" section controls which files are to be processed, and what is to 
be done (actions). This is described below.

Special case: shared storages
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Since shared storages are "owned" by the UNICORE server and used by multiple users,
data-triggered processing requires a valid Unix user ID in order to list files independently
of any actual user. Therefore the 'triggerUserID' property is used to configure which user
ID should be used (as always in UNICORE, this cannot be 'root', and multiuser operation 
requires the TSI!).

For example, you might have a project storage configured like this:

----------------------------
#
# Shares
#
coreServices.sms.storage.enabledStorages=PROJECTS

coreServices.sms.storage.PROJECTS.name=projects
coreServices.sms.storage.PROJECTS.description=Shared projects
coreServices.sms.storage.PROJECTS.path=/opt/shared-data
coreServices.sms.storage.PROJECTS.defaultUmask=007
coreServices.sms.storage.PROJECTS.enableTrigger=true
coreServices.sms.storage.PROJECTS.triggerUserID=projects01
----------------------------

Here the scanning settings are only evaluated top-level.

For each included directory, a separate scan is done, controlled by 
another +.UNICORE_Rules+ file in that directory. So the directory 
structure could look like this:

----------------------------
├── dir1
│   ├── ...
│   └── .UNICORE_Rules
├── dir2
│   ├── ...
│   └── .UNICORE_Rules
├── dir3
│   ├── ...
│   └── .UNICORE_Rules
└── .UNICORE_Rules
----------------------------

The top-level +.UNICORE_Rules+ file must list the included directories.
Processing the included directories is then done using the owner of
that directory.

Rules
~~~~~

The "Rules" section in the +.UNICORE_Rules+ file is a list
of file match specifications together with a definition of
an "action", i.e. what should be done for those files that match.

The general syntax is

----------------------------
{
"DirectoryScan": {
  "IncludeDirs": [...],
  "ExcludeDirs": [...]
},

"Rules": [
  {
    "Name": "foo",
    "Match": ".*incoming/file_.*",
    "Action": { ... }
   }
]
}
----------------------------

The mandatory elements are

    * +Name+ : the name of the rule. This is useful when checking the logfiles,
    * +Match+ : a regular expression defining which file paths (relative to 
      storage root) should be processed,
    * +Action+ : the action to be taken.

==== Variables
The following variables can be used in the +Action+ description.

    * +UC_BASE_DIR+ : the storage root directory
    * +UC_CURRENT_DIR+ : the absolute path to the parent directory of the current file 
    * +UC_FILE_PATH+ : the full path to the current file
    * +UC_FILE_NAME+ : the file name

==== Scripts
This type of action defines a script that is executed on the cluster 
login node (TSI node). 

----------------------------
"Action":
{
 "Name": "local_example",
 "Type": "LOCAL",
 "Command": "/bin/md5sum ${UC_FILE_PATH}",
 "Outcome": "output_directory",
 "Stdout": "${UC_FILE_NAME}.md5",
 "Stderr": "${UC_FILE_NAME}.error"
}
----------------------------

==== Batch jobs
This type of action defines a batch job that is submitted to the resource 
management system of your cluster.

----------------------------
"Action":
{
 "Name": "batch_example",
 "Type": "BATCH",
 "Job": { ... }
}
----------------------------

The +Job+ element is a normal UNICORE job in the same syntax as used for
the UCC commandline client.

==== Automated metadata extraction


----------------------------
"Action":
{
 "Name": "extract_example",
 "Type": "EXTRACT",
 "Settings": { ... }
}
----------------------------

This action will extract metadata from the file. The +Settings+ element 
is currently unused.
